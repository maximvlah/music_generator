{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('music': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d7a8bc76ab6e45d1812f82a5f3630588c9b96ae0b6fcc31e1268834529242d99"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convert Midi Files to Text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of processors:  8\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "# !pip install music21\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "import concurrent\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notes(filepath):\n",
    "    ''' Extract notes from a single MIDI file'''\n",
    "    notes = []\n",
    "    # print(\"Parsing %s\" % file)\n",
    "\n",
    "    midi = converter.parse(filepath)\n",
    "\n",
    "    notes_to_parse = None\n",
    "\n",
    "    try: # file has instrument parts\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_to_parse = s2.parts[1].recurse() \n",
    "    except: # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    print(f'Conversion of \"{filepath}\" completed')\n",
    "\n",
    "    with open(filepath.replace('.mid',''), 'wb') as f:\n",
    "        pickle.dump(notes, f)\n",
    "\n",
    "    # return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(path):\n",
    "    print(path)\n",
    "    return path[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get all the notes and chords from the midi files\"\"\"\n",
    "\n",
    "# notes = []\n",
    "\n",
    "#divide list of paths in n equal parts where n = number of cpus available\n",
    "n = int(len(paths) / mp.cpu_count()) \n",
    "paths_split = [paths[i * n:(i + 1) * n] for i in range((len(paths) + n - 1) // n )]  \n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    results = executor.map(func, paths_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(r\"data\\classical_composers\\midi\\*\\*.mid\")\n",
    "paths = [path.replace('\\\\','/') for path in paths]\n",
    "\n",
    "# paths\n",
    "paths = paths[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversion of \"data/classical_composers/midi/albeniz/alb_esp2.mid\" completed\n"
     ]
    }
   ],
   "source": [
    "extract_notes(paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get all the notes and chords from the midi files\"\"\"\n",
    "\n",
    "# notes = []\n",
    "\n",
    "#divide list of paths in n equal parts where n = number of cpus available\n",
    "n = int(len(paths) / mp.cpu_count()) \n",
    "paths_split = [paths[i * n:(i + 1) * n] for i in range((len(paths) + n - 1) // n )]  \n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    # results = [executor.submit(extract_notes, paths_split[i]) for i in range(mp.cpu_count())]\n",
    "    results = executor.map(extract_notes, paths_split)\n",
    "\n",
    "    # for f in concurrent.futures.as_completed(results):\n",
    "    #     print(f.result())\n",
    "# #save as pickle file\n",
    "# with open('data/notes', 'wb') as filepath:\n",
    "#     pickle.dump(notes, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0891c282557c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\music\\lib\\concurrent\\futures\\process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \"\"\"\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\music\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    609\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\music\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\music\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicData:\n",
    "    def __init__(self, \n",
    "                 paths, \n",
    "                 sequence_length = 32, \n",
    "                 load = False):\n",
    "\n",
    "        \n",
    "        if load: #load already pre-processed data\n",
    "            with open('data/notes', 'rb') as f:\n",
    "                self.notes = pickle.load(f)\n",
    "\n",
    "        else: #pre-process\n",
    "            print('Parsing midi files:')\n",
    "            time.sleep(1)\n",
    "            self.notes = self.get_notes(paths)\n",
    "\n",
    "        # get amount of pitch names\n",
    "        self.n_vocab = len(set(self.notes))\n",
    "        # prepare data for training\n",
    "        self.X, self.y = self.notes_to_seq(self.notes, self.n_vocab, sequence_length)\n",
    "\n",
    "    # https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "    def get_notes(self, paths):\n",
    "        \"\"\" Get all the notes and chords from the midi files\"\"\"\n",
    "        notes = []\n",
    "\n",
    "        #loop over each file path\n",
    "        for file in tqdm(paths):\n",
    "            midi = converter.parse(file)\n",
    "\n",
    "            # print(\"Parsing %s\" % file)\n",
    "\n",
    "            notes_to_parse = None\n",
    "\n",
    "            try: # file has instrument parts\n",
    "                s2 = instrument.partitionByInstrument(midi)\n",
    "                notes_to_parse = s2.parts[1].recurse() \n",
    "            except: # file has notes in a flat structure\n",
    "                notes_to_parse = midi.flat.notes\n",
    "\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "        #save as pickle file\n",
    "        with open('data/notes', 'wb') as filepath:\n",
    "            pickle.dump(notes, filepath)\n",
    "\n",
    "        return notes\n",
    "\n",
    "\n",
    "\n",
    "    def notes_to_seq(self, notes, n_vocab,sequence_length):\n",
    "        \"\"\" Prepare the sequences used by the model \"\"\"\n",
    "\n",
    "        # get all pitch names\n",
    "        pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "        # create a dictionary to map pitches to integers\n",
    "        note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # create input sequences and the corresponding outputs\n",
    "        for i in range(0, len(notes) - sequence_length):\n",
    "            sequence_in = notes[i:i + sequence_length]\n",
    "            sequence_out = notes[i + sequence_length]\n",
    "            X.append([note_to_int[char] for char in sequence_in])\n",
    "            y.append(note_to_int[sequence_out])\n",
    "\n",
    "        n_patterns = len(X)\n",
    "\n",
    "        # reshape the input into a format compatible with LSTM layers\n",
    "        X = numpy.reshape(X, (n_patterns, sequence_length, 1))\n",
    "        # normalize input\n",
    "        X = X / float(n_vocab)\n",
    "\n",
    "        y = np_utils.to_categorical(y)\n",
    "\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsing midi files:\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "data = MusicData(paths[:5],100,load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3997, 100, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "data.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}